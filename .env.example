# Claude Research Projects - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# CORE CONFIGURATION
# =============================================================================

# Project root directory (absolute path)
PROJECT_ROOT=/Users/ma/claude-research-projects

# GitHub configuration
GITHUB_TOKEN=your_github_personal_access_token_here
GITHUB_USERNAME=machiabeli

# =============================================================================
# CLAUDE CODE CONFIGURATION
# =============================================================================

# Claude API (if using programmatic access)
CLAUDE_API_KEY=your_claude_api_key_here

# Claude Code on Web session preferences
CLAUDE_MODEL=claude-sonnet-4-5-20250929
CLAUDE_MAX_TOKENS=200000
CLAUDE_TEMPERATURE=0.7

# =============================================================================
# MONITORING SYSTEM
# =============================================================================

# Dashboard configuration
MONITORING_PORT=8050
MONITORING_HOST=localhost
MONITORING_REFRESH_INTERVAL=30  # seconds

# Metrics storage
METRICS_DB_PATH=${PROJECT_ROOT}/monitoring/data/metrics.db
LOGS_PATH=${PROJECT_ROOT}/monitoring/data/logs

# Alert thresholds
ALERT_ERROR_RATE_THRESHOLD=0.1
ALERT_CREDIT_WARNING_PERCENT=20

# =============================================================================
# PROJECT 1: HERETIC ENHANCEMENT (AI/ML)
# =============================================================================

# Heretic fork configuration
HERETIC_REPO_PATH=${PROJECT_ROOT}/projects/01-ai-ml-heretic-enhancement/heretic
HERETIC_FORK_URL=https://github.com/machiabeli/heretic.git

# Python environment
HERETIC_PYTHON_VERSION=3.10
HERETIC_VENV_PATH=${PROJECT_ROOT}/projects/01-ai-ml-heretic-enhancement/.venv

# GPU configuration
HERETIC_USE_GPU=true
HERETIC_CUDA_VERSION=12.1
HERETIC_GPU_MEMORY_LIMIT=16GB  # Adjust based on your hardware

# Model testing
HERETIC_TEST_MODEL=Qwen/Qwen2.5-7B-Instruct  # Smaller model for testing
HERETIC_PRODUCTION_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Experiment tracking
HERETIC_EXPERIMENT_DIR=${PROJECT_ROOT}/projects/01-ai-ml-heretic-enhancement/experiments
HERETIC_USE_MLFLOW=true
HERETIC_MLFLOW_URI=${PROJECT_ROOT}/projects/01-ai-ml-heretic-enhancement/mlruns

# Papers to implement
HERETIC_PAPERS="2505.00509,2502.17601,2507.21509,2410.16314,2502.00669,2406.07522"

# =============================================================================
# PROJECT 2: DEVELOPER TOOLS (TBD)
# =============================================================================

# DEVTOOLS_REPO_PATH=${PROJECT_ROOT}/projects/02-devtools-TBD
# Add configuration when project is defined

# =============================================================================
# PROJECT 3: DATA PROCESSING (TBD)
# =============================================================================

# DATA_PROCESSING_PATH=${PROJECT_ROOT}/projects/03-data-processing-TBD
# Add configuration when project is defined

# =============================================================================
# PROJECT 4: WEB/API SERVICES (TBD)
# =============================================================================

# WEB_API_PATH=${PROJECT_ROOT}/projects/04-web-api-TBD
# Add configuration when project is defined

# =============================================================================
# PROJECT 5: SCIENTIFIC COMPUTING (TBD)
# =============================================================================

# SCIENTIFIC_COMPUTING_PATH=${PROJECT_ROOT}/projects/05-scientific-computing-TBD
# Add configuration when project is defined

# =============================================================================
# DOCKER CONFIGURATION
# =============================================================================

# Docker settings
DOCKER_BUILD_CONTEXT=${PROJECT_ROOT}
DOCKER_REGISTRY=ghcr.io
DOCKER_IMAGE_PREFIX=${GITHUB_USERNAME}/claude-research

# Container resource limits
DOCKER_CPU_LIMIT=4
DOCKER_MEMORY_LIMIT=16g
DOCKER_SHM_SIZE=8g  # Important for PyTorch

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json  # or "text"

# Git configuration
GIT_AUTO_COMMIT=false
GIT_COMMIT_PREFIX="[Research]"

# Testing
RUN_TESTS_ON_IMPLEMENTATION=true
COVERAGE_THRESHOLD=80

# Benchmarking
BENCHMARK_ITERATIONS=5
BENCHMARK_RANDOM_SEEDS="42,123,456,789,1011"

# =============================================================================
# OPTIMIZATION SETTINGS
# =============================================================================

# Credit optimization
ESTIMATE_TOKENS_BEFORE_RUN=true
MAX_TOKENS_PER_SESSION=150000
PAUSE_ON_CREDIT_WARNING=true

# Parallel execution (for independent tasks)
MAX_PARALLEL_PROJECTS=3
ENABLE_PARALLEL_PAPER_ANALYSIS=true

# =============================================================================
# NOTIFICATION SETTINGS
# =============================================================================

# Slack notifications (optional)
SLACK_WEBHOOK_URL=
SLACK_CHANNEL=#research-notifications
NOTIFY_ON_COMPLETION=true
NOTIFY_ON_ERROR=true

# Email notifications (optional)
EMAIL_ENABLED=false
EMAIL_SMTP_HOST=
EMAIL_SMTP_PORT=587
EMAIL_FROM=
EMAIL_TO=

# =============================================================================
# ARXIV API
# =============================================================================

# ArXiv API configuration (if using MCP)
ARXIV_API_DELAY=3  # seconds between requests (be respectful)
ARXIV_MAX_RESULTS=10
ARXIV_DOWNLOAD_PDF=true
ARXIV_PDF_DIR=${PROJECT_ROOT}/papers

# =============================================================================
# EXTERNAL SERVICES (OPTIONAL)
# =============================================================================

# Weights & Biases
WANDB_API_KEY=
WANDB_PROJECT=claude-research
WANDB_ENTITY=

# Hugging Face (for model downloads)
HF_TOKEN=
HF_CACHE_DIR=${PROJECT_ROOT}/.cache/huggingface

# OpenAI (for comparisons/baselines)
OPENAI_API_KEY=

# =============================================================================
# SECURITY
# =============================================================================

# Sandbox mode (restrict network access)
ENABLE_SANDBOX=false
ALLOWED_DOMAINS="github.com,arxiv.org,huggingface.co,pypi.org"

# Code execution limits
MAX_EXECUTION_TIME=3600  # seconds
MEMORY_LIMIT_MB=16384

# =============================================================================
# MISC
# =============================================================================

# Timezone
TZ=America/New_York

# Temporary files
TMP_DIR=${PROJECT_ROOT}/.tmp

# Cache
CACHE_DIR=${PROJECT_ROOT}/.cache
CACHE_ENABLED=true

# Debug mode
DEBUG=false
VERBOSE=false
